{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FSe27W6zvtx4","executionInfo":{"status":"ok","timestamp":1680586243308,"user_tz":-120,"elapsed":1912,"user":{"displayName":"Evgeniya Ishkina","userId":"15312785639436921440"}},"outputId":"a54257a6-1cf4-43d7-9398-a2455d0e9042"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","metadata":{"id":"ypt7ymI8X-rM"},"source":["# Word2vec et autres embeddings"]},{"cell_type":"markdown","metadata":{"id":"Z3sSyfHaX-rN"},"source":["![word2vec](https://cdn-images-1.medium.com/max/2600/1*sXNXYfAqfLUeiDXPCo130w.png)"]},{"cell_type":"markdown","metadata":{"id":"0oH_UDyFX-rO"},"source":["Le `word embedding` est capable de capturer le contexte, la similarité sémantique et syntaxique (genre, synonymes, …) d’un mot et fournir une représentation vectorielle *dense*.\n","\n","Il existe trois scénarios pour produire des représentations vectorielles des documents :\n","- Utiliser un modèle pré-entraîné\n","- Entraîner son propre modèle \n","- Prendre un modèle pré-entraîné (par exemple, [fastText](https://fasttext.cc/docs/en/english-vectors.html) ou [GloVe](https://nlp.stanford.edu/projects/glove/) et l'affiner.\n","\n","Pour récupérer un modèle pré-entraîné ou entraîner son propre modèle, on peut utiliser la librarie `gensim`, le module : `models.word2vec`. Plus de [détails](https://radimrehurek.com/gensim/models/word2vec.html)."]},{"cell_type":"markdown","metadata":{"id":"yXNm8flVX-rP"},"source":["## Modèle pré-entraîné avec la méthode word2vec\n","\n","Pour charger des vecteurs de type `word2vec` et travailler avec on utilise la classe `KeyedVectors`. Cette classe contienne une méthode `load_word2vec_format` pour charger le modèle entraîné avec la méthode word2vec (à partir d'un fichier texte ou d'un fichier binaire) et `load` pour charger un modèle entraîné avec une autre méthode (*glove, fasttext*).\n","\n","Source: \n","\n","    @misc{fauconnier_2015,\n","        author = {Fauconnier, Jean-Philippe},\n","        title = {French Word Embeddings},\n","        url = {http://fauconnier.github.io},\n","        year = {2015}}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sTLnNKaNX-rP"},"outputs":[],"source":["import re\n","import logging\n","import pandas as pd\n","\n","import nltk.data \n","from nltk.corpus import stopwords\n","from nltk.tokenize import sent_tokenize, RegexpTokenizer\n","# nltk.download('punkt')\n","\n","import gensim\n","from gensim.models import word2vec, KeyedVectors"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nu7W42OILlyS","executionInfo":{"status":"ok","timestamp":1680554055637,"user_tz":-120,"elapsed":1886,"user":{"displayName":"Evgeniya Ishkina","userId":"15312785639436921440"}},"outputId":"e468ad0f-3a06-46f3-ddd2-055a82cefd69"},"outputs":[{"output_type":"stream","name":"stdout","text":["[('intéressante', 0.6818215847015381), ('instructif', 0.6677659749984741), ('assez', 0.6302736401557922), ('intéressants', 0.6282306909561157), ('très', 0.6215654611587524), ('utile', 0.5970137119293213), ('rébarbatif', 0.5915195345878601), ('intéressantes', 0.5864251255989075), ('judicieux', 0.5620384216308594), ('beaucoup', 0.5607017874717712)]\n","0.6323689\n"]}],"source":["model_fr = KeyedVectors.load_word2vec_formodel = KeyedVectors.load_word2vec_format(\"/content/drive/My Drive/NLP/frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin\", binary=True, unicode_errors=\"ignore\")\n","print(model_fr.most_similar(\"intéressant\"))\n","print(model_fr.similarity('formation', 'professionnalisante'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N0L5_TCQX-rf","outputId":"fb244016-fcb0-4ee1-9661-af80d01e8c62","executionInfo":{"status":"ok","timestamp":1680554058547,"user_tz":-120,"elapsed":239,"user":{"displayName":"Evgeniya Ishkina","userId":"15312785639436921440"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[('reine', 0.6945513486862183), ('duchesse', 0.6247551441192627), ('épouse', 0.6083102822303772)]\n","[('france', 0.5135271549224854), ('nanterre', 0.45087674260139465), ('bd', 0.43005678057670593)]\n","[('bretons', 0.6322782039642334), ('bretonne', 0.6221523880958557), ('bretonnes', 0.5482804775238037)]\n"]}],"source":["# (roi - homme) + femme = ?\n","print(model_fr.most_similar(positive=['roi', 'femme'], negative=['homme'], topn=3))\n","# (espagne - madrid) + paris = ?\n","print(model_fr.most_similar(positive=['espagne', 'paris'], negative=['madrid'], topn=3))\n","# (basques - espagne) + bretagne = ?\n","print(model_fr.most_similar(positive=['basques', 'bretagne'], negative=['espagne'], topn=3))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"DrN2Jc31X-rh","outputId":"1149789f-6d9a-4ad4-cda0-2e544ae8946c","executionInfo":{"status":"ok","timestamp":1680554061824,"user_tz":-120,"elapsed":242,"user":{"displayName":"Evgeniya Ishkina","userId":"15312785639436921440"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'ananas'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":14}],"source":["model_fr.doesnt_match('basque gascon ananas breton'.split())"]},{"cell_type":"code","source":["del model_fr"],"metadata":{"id":"-yl837bS07ug"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_fr_postag = KeyedVectors.load_word2vec_formodel = KeyedVectors.load_word2vec_format(\"/content/drive/My Drive/NLP/frWac_postag_no_phrase_1000_skip_cut100.bin\", binary=True, unicode_errors=\"ignore\")\n","print(model_fr_postag.most_similar(\"intéressant_a\"))\n","\n","del model_fr_postag"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6L3kRHDA047t","executionInfo":{"status":"ok","timestamp":1680554107299,"user_tz":-120,"elapsed":7535,"user":{"displayName":"Evgeniya Ishkina","userId":"15312785639436921440"}},"outputId":"5af3e278-4788-4f5e-fb8e-0f75e2bcebbb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('très_adv', 0.5709680914878845), ('assez_adv', 0.5124066472053528), ('inconvénient_a', 0.512165904045105), ('inconvénients_n', 0.5095574259757996), ('avantages_et', 0.48624387383461), ('avantages_n', 0.48457926511764526), ('plutôt_adv', 0.4844917356967926), ('ciao_n', 0.4828088879585266), ('instructif_a', 0.4705738127231598), ('beaucoup_adv', 0.468425452709198)]\n"]}]},{"cell_type":"markdown","metadata":{"id":"rvYSb3NICFKA"},"source":["## Modèle pré-entraîné : GloVe\n","\n","Lien pour le téléchargement du modèle pré-entraîné: https://nlp.stanford.edu/projects/glove/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4SD8ZgCtCFKF"},"outputs":[],"source":["# import numpy as np\n","\n","# glove = {}\n","# with open('/content/drive/My Drive/NLP/glove.6B/glove.6B.200d.txt', 'r') as f:\n","#     for line in f:\n","#         word, embedding = line.split(' ',1)\n","#         wordEmbedding = np.array([float(value) for value in embedding[1:].split(' ')])\n","#         glove[word] = wordEmbedding\n","\n","# print(len(glove))"]},{"cell_type":"code","source":["# from gensim.test.utils import datapath, get_tmpfile\n","# from gensim.models import KeyedVectors\n","# from gensim.scripts.glove2word2vec import glove2word2vec\n","\n","# glove_file = datapath('/content/drive/My Drive/NLP/glove.6B/glove.6B.200d.txt')\n","# tmp_file = get_tmpfile(\"glove.6B.200d.vec\")\n","# _ = glove2word2vec(glove_file, tmp_file)\n","# model_glove = KeyedVectors.load_word2vec_format(tmp_file)\n","# model_glove.save_word2vec_format(\"/content/drive/My Drive/NLP/glove.6B/glove.6B.200d.bin\", binary=True)"],"metadata":{"id":"CqpNRAKrSWB9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_glove = KeyedVectors.load_word2vec_formodel = KeyedVectors.load_word2vec_format(\"/content/drive/My Drive/NLP/glove.6B/glove.6B.200d.bin\", binary=True, unicode_errors=\"ignore\")\n","\n","# (king - man) + woman = ?\n","print(model_glove.most_similar(positive=['king', 'woman'], negative=['man']))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pu3vMs7KTuS2","executionInfo":{"status":"ok","timestamp":1680554184184,"user_tz":-120,"elapsed":7577,"user":{"displayName":"Evgeniya Ishkina","userId":"15312785639436921440"}},"outputId":"c09f1ab6-cc2f-4b1b-e106-59245bec8635"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('queen', 0.6978678107261658), ('princess', 0.6081745028495789), ('monarch', 0.5889754891395569), ('throne', 0.5775108933448792), ('prince', 0.5750998258590698), ('elizabeth', 0.5463595986366272), ('daughter', 0.5399126410484314), ('kingdom', 0.5318052768707275), ('mother', 0.5168544054031372), ('crown', 0.5164473056793213)]\n"]}]},{"cell_type":"code","source":["del model_glove"],"metadata":{"id":"bNMCyvPi1E3p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hiJZL8hqCFKJ"},"source":["## Modèle pré-entraîné : fastText\n","\n","FastText utilise non seulement des vecteurs de mots, mais aussi des vecteurs de n-grammes. Dans le corpus, chaque mot est automatiquement représenté comme un ensemble de n-grammes de caractères. Par exemple, si nous fixons n=3, un vecteur pour le mot \"where\" sera représenté par la somme des vecteurs des trigrammes suivants : \"<wh\", \"whe\", \"her\", \"ere\", \"re>\" (où \"<\" et \">\" sont des symboles indiquant le début et la fin d'un mot). Cela permet de travailler efficacement avec des textes contenant des erreurs et des fautes de frappe.\n","\n","* [Article](https://aclweb.org/anthology/Q17-1010)\n","* [Site](https://fasttext.cc/)\n","* [Get started](https://fasttext.cc/docs/en/support.html)\n","* [Github](https://github.com/facebookresearch/fasttext)\n","\n","Pour python il existe une librarie - `fasttext`. Si on récupère des fichiers de modèles, on peut utiliser `gensim`.\n","\n","Sur le [site](https://fasttext.cc/docs/en/crawl-vectors.html) on trouve des modèles pré-entraînés pour 157 langues (dont le français)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UgJotqU5Llyb"},"outputs":[],"source":["# ! pip install fasttext"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b053l95OCFKM"},"outputs":[],"source":["import fasttext\n","# import fasttext.util\n","# fasttext.util.download_model('en', if_exists='ignore') "]},{"cell_type":"code","source":["# !cp \"/content/cc.en.300.bin\" \"/content/drive/My Drive/NLP/\""],"metadata":{"id":"-c6ckceBsny4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ft_en = fasttext.load_model('/content/drive/My Drive/NLP/cc.en.300.bin')\n","\n","# print(ft_en['model'])\n","print(ft_en.get_nearest_neighbors('intelligence'))\n","print(ft_en.get_analogies(\"woman\", \"man\", \"actor\"))\n","\n","# Comme le modèle est entraîné sur des n-grammes de caractères, \n","# il n'y a pas de problème de OOV (out of vocabulary)\n","print(ft_en.get_nearest_neighbors('formatoin'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tHUQqrI5juOm","executionInfo":{"status":"ok","timestamp":1680553781169,"user_tz":-120,"elapsed":60151,"user":{"displayName":"Evgeniya Ishkina","userId":"15312785639436921440"}},"outputId":"cef4e809-8faa-4f68-dff1-6a13e4c5b846"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"]},{"output_type":"stream","name":"stdout","text":["[(0.7630482912063599, 'inteligence'), (0.7555618286132812, 'intelligence.The'), (0.7255445718765259, 'intelligence-'), (0.716752290725708, 'intellgence'), (0.7112532258033752, 'intellegence'), (0.709306001663208, 'Intelligence'), (0.7025996446609497, 'non-intelligence'), (0.6886445879936218, 'intelligence.'), (0.6828545928001404, 'intelligence.But'), (0.6662881970405579, 'intelligenc')]\n","[(0.8941132426261902, 'actress'), (0.7075303196907043, 'actresses'), (0.6792172193527222, 'actress-'), (0.6782666444778442, 'actresss'), (0.6682973504066467, 'actress.'), (0.6645402908325195, 'Actress'), (0.659998893737793, 'actress.She'), (0.6558604836463928, 'actres'), (0.646649956703186, 'actess'), (0.6443707346916199, 'actress.The')]\n","[(0.5347930192947388, 'informatoin'), (0.3836231231689453, 'Year.ReplyDeleteAdd'), (0.3629437983036041, 'itself.ReplyDeleteAdd'), (0.3616984486579895, 'serviceReplyDeleteAdd'), (0.3609582483768463, 'money.ReplyDeleteAdd'), (0.35249876976013184, 'service.ReplyDeleteAdd'), (0.352337121963501, 'pattern.ReplyDeleteAdd'), (0.35117432475090027, 'going.ReplyDeleteAdd'), (0.34717637300491333, 'name.ReplyDeleteAdd'), (0.3467143476009369, 'food.ReplyDeleteAdd')]\n"]}]},{"cell_type":"code","source":["del ft_en"],"metadata":{"id":"33XUEUCP0fTZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZNHMtmbqX-rl"},"source":["## Entraînement d'un modèle word2vec\n","\n","* Dataset: IMDB Movie Reviews [source sur kaggle](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews) ou [lien stanford](http://ai.stanford.edu/~amaas/data/sentiment/)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dkq3AXPbCFKh"},"outputs":[],"source":["import pandas as pd\n","\n","pd.set_option('display.max_columns', None)  \n","pd.set_option('display.expand_frame_repr', False)\n","pd.set_option('max_colwidth', 800)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B2wv-vSxX-ro","outputId":"2bc1f949-d79d-4ef7-a934-72778ea6699c","executionInfo":{"status":"ok","timestamp":1680554208520,"user_tz":-120,"elapsed":3341,"user":{"displayName":"Evgeniya Ishkina","userId":"15312785639436921440"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(50000, 2)"]},"metadata":{},"execution_count":22}],"source":["data = pd.read_csv(\"/content/drive/My Drive/NLP/IMDB Dataset.csv\")\n","data.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":684},"id":"eEGmrh-nX-rq","outputId":"5e1177f8-4d1c-4872-dec9-77888b0f3022","executionInfo":{"status":"ok","timestamp":1680554215534,"user_tz":-120,"elapsed":248,"user":{"displayName":"Evgeniya Ishkina","userId":"15312785639436921440"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            review sentiment\n","0  One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangst...  positive\n","1  A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. It plays on ou...  positive\n","2  I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.<br /><br />This was the most I'd laughed at one of Woody's comedies in years (dare I say a decade?). While I've never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.<br /><br />This may not be the crown jewel of h...  positive\n","3                                                     Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.  negative\n","4  Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situations we encounter. <br /><br />This being a variation on the Arthur Schnitzler's play about the same theme, the director transfers the action to the present time New York where all these different characters meet and connect. Each one is connected in one way, or another to the next person, but no one seems to know the previous point of contact. Stylishly, the film has a sophisticated luxurious look. We are taken to see how these people live and the world they live in their own habitat.<br /><br />The only thing one gets out of all these ...  positive"],"text/html":["\n","  <div id=\"df-bd44e20b-af49-491b-98e1-05c695a44f62\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.&lt;br /&gt;&lt;br /&gt;The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.&lt;br /&gt;&lt;br /&gt;It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangst...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. &lt;br /&gt;&lt;br /&gt;The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. &lt;br /&gt;&lt;br /&gt;The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. It plays on ou...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.&lt;br /&gt;&lt;br /&gt;This was the most I'd laughed at one of Woody's comedies in years (dare I say a decade?). While I've never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.&lt;br /&gt;&lt;br /&gt;This may not be the crown jewel of h...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet &amp; his parents are fighting all the time.&lt;br /&gt;&lt;br /&gt;This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.&lt;br /&gt;&lt;br /&gt;OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing &amp; arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.&lt;br /&gt;&lt;br /&gt;3 out of 10 just for the well playing parents &amp; descent dialogs. As for the shots with Jake: just ignore them.</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situations we encounter. &lt;br /&gt;&lt;br /&gt;This being a variation on the Arthur Schnitzler's play about the same theme, the director transfers the action to the present time New York where all these different characters meet and connect. Each one is connected in one way, or another to the next person, but no one seems to know the previous point of contact. Stylishly, the film has a sophisticated luxurious look. We are taken to see how these people live and the world they live in their own habitat.&lt;br /&gt;&lt;br /&gt;The only thing one gets out of all these ...</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd44e20b-af49-491b-98e1-05c695a44f62')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-bd44e20b-af49-491b-98e1-05c695a44f62 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-bd44e20b-af49-491b-98e1-05c695a44f62');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":23}],"source":["data.head()"]},{"cell_type":"markdown","metadata":{"id":"oIZaQ3kYX-rt"},"source":["### Nettoyage et tokénisation des documents\n","\n","Nettoyage\n","\n","* supprimer des liens hypertexte et des balises html\n","* supprimer des caractères autres que des lettres\n","* mettre les textes en minuscules"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nA2yevLICFKl"},"outputs":[],"source":["from bs4 import BeautifulSoup\n","from tqdm.notebook import tqdm\n","from multiprocessing import Pool\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0-09WjJNCFKm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680561479257,"user_tz":-120,"elapsed":2029,"user":{"displayName":"Evgeniya Ishkina","userId":"15312785639436921440"}},"outputId":"620a2e1e-5502-40ce-b668-a9d82b52c355"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}],"source":["import nltk\n","nltk.download('punkt')\n","# Sentences tokenizer\n","tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"irbunSOfX-rt"},"outputs":[],"source":["def review_to_words(review, remove_stopwords=False):\n","    # supprimer des liens hypertextes\n","    review = re.sub(r\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\", \" \", review)\n","    # supprimer des balises html\n","    review_text = BeautifulSoup(review, \"lxml\").get_text()\n","    # remplacer les caractères autres que des lettres par des expaces\n","    review_text = re.sub(\"[^a-zA-Z]\", \" \", review_text)\n","    # mettre en minuscules et convertir en liste de mots\n","    words = review_text.lower().split()\n","    if remove_stopwords:\n","        # supprimer les mots vides de la langue anglaise\n","        words = [w for w in words if not w in stopwords.words(\"english\")]\n","    return(words)\n","\n","def review_to_sentences(review, tokenizer=tokenizer, remove_stopwords=False):\n","    # token = phrase\n","    raw_sentences = tokenizer.tokenize(review.strip())\n","    sentences = []\n","    for raw_sentence in raw_sentences:\n","        if len(raw_sentence) > 0:\n","            sentences.append(review_to_words(raw_sentence, remove_stopwords))\n","    return sentences"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"referenced_widgets":["0c838ab8723146f480cc6368657590c5","4d321c1988b744929c660d9a18e93a1d","c0c43adbc9b946ee8f07c6c80f562a89","ac0f910945c344de99abf6babe8b6de7","7e6b7c3b4d1e46c2a84242100d0abfa7","f38a0cedf6fe4ac4802ba5c48dcd9bff","2598fd66c334422cb87f21e01418286c","fc5d696d5c1846a382c7b602b971ad29","08b7866d34144d119e3a5f493dd172ea","c9d120308f884283a8be29b4f002df1d","4f92d894df644589a4429c6cde910e59"],"base_uri":"https://localhost:8080/","height":104},"id":"PUMZZKpXCFKo","outputId":"79ad69a0-7282-463b-8d60-b8dd548fd5f4","executionInfo":{"status":"ok","timestamp":1680554443907,"user_tz":-120,"elapsed":209220,"user":{"displayName":"Evgeniya Ishkina","userId":"15312785639436921440"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/50000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c838ab8723146f480cc6368657590c5"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["50000\n","[['one', 'of', 'the', 'other', 'reviewers', 'has', 'mentioned', 'that', 'after', 'watching', 'just', 'oz', 'episode', 'you', 'll', 'be', 'hooked'], ['they', 'are', 'right', 'as', 'this', 'is', 'exactly', 'what', 'happened', 'with', 'me', 'the', 'first', 'thing', 'that', 'struck', 'me', 'about', 'oz', 'was', 'its', 'brutality', 'and', 'unflinching', 'scenes', 'of', 'violence', 'which', 'set', 'in', 'right', 'from', 'the', 'word', 'go'], ['trust', 'me', 'this', 'is', 'not', 'a', 'show', 'for', 'the', 'faint', 'hearted', 'or', 'timid'], ['this', 'show', 'pulls', 'no', 'punches', 'with', 'regards', 'to', 'drugs', 'sex', 'or', 'violence'], ['its', 'is', 'hardcore', 'in', 'the', 'classic', 'use', 'of', 'the', 'word', 'it', 'is', 'called', 'oz', 'as', 'that', 'is', 'the', 'nickname', 'given', 'to', 'the', 'oswald', 'maximum', 'security', 'state', 'penitentary'], ['it', 'focuses', 'mainly', 'on', 'emerald', 'city', 'an', 'experimental', 'section', 'of', 'the', 'prison', 'where', 'all', 'the', 'cells', 'have', 'glass', 'fronts', 'and', 'face', 'inwards', 'so', 'privacy', 'is', 'not', 'high', 'on', 'the', 'agenda'], ['em', 'city', 'is', 'home', 'to', 'many', 'aryans', 'muslims', 'gangstas', 'latinos', 'christians', 'italians', 'irish', 'and', 'more', 'so', 'scuffles', 'death', 'stares', 'dodgy', 'dealings', 'and', 'shady', 'agreements', 'are', 'never', 'far', 'away', 'i', 'would', 'say', 'the', 'main', 'appeal', 'of', 'the', 'show', 'is', 'due', 'to', 'the', 'fact', 'that', 'it', 'goes', 'where', 'other', 'shows', 'wouldn', 't', 'dare'], ['forget', 'pretty', 'pictures', 'painted', 'for', 'mainstream', 'audiences', 'forget', 'charm', 'forget', 'romance', 'oz', 'doesn', 't', 'mess', 'around'], ['the', 'first', 'episode', 'i', 'ever', 'saw', 'struck', 'me', 'as', 'so', 'nasty', 'it', 'was', 'surreal', 'i', 'couldn', 't', 'say', 'i', 'was', 'ready', 'for', 'it', 'but', 'as', 'i', 'watched', 'more', 'i', 'developed', 'a', 'taste', 'for', 'oz', 'and', 'got', 'accustomed', 'to', 'the', 'high', 'levels', 'of', 'graphic', 'violence'], ['not', 'just', 'violence', 'but', 'injustice', 'crooked', 'guards', 'who', 'll', 'be', 'sold', 'out', 'for', 'a', 'nickel', 'inmates', 'who', 'll', 'kill', 'on', 'order', 'and', 'get', 'away', 'with', 'it', 'well', 'mannered', 'middle', 'class', 'inmates', 'being', 'turned', 'into', 'prison', 'bitches', 'due', 'to', 'their', 'lack', 'of', 'street', 'skills', 'or', 'prison', 'experience', 'watching', 'oz', 'you', 'may', 'become', 'comfortable', 'with', 'what', 'is', 'uncomfortable', 'viewing', 'thats', 'if', 'you', 'can', 'get', 'in', 'touch', 'with', 'your', 'darker', 'side']] [['a', 'wonderful', 'little', 'production'], ['the', 'filming', 'technique', 'is', 'very', 'unassuming', 'very', 'old', 'time', 'bbc', 'fashion', 'and', 'gives', 'a', 'comforting', 'and', 'sometimes', 'discomforting', 'sense', 'of', 'realism', 'to', 'the', 'entire', 'piece'], ['the', 'actors', 'are', 'extremely', 'well', 'chosen', 'michael', 'sheen', 'not', 'only', 'has', 'got', 'all', 'the', 'polari', 'but', 'he', 'has', 'all', 'the', 'voices', 'down', 'pat', 'too'], ['you', 'can', 'truly', 'see', 'the', 'seamless', 'editing', 'guided', 'by', 'the', 'references', 'to', 'williams', 'diary', 'entries', 'not', 'only', 'is', 'it', 'well', 'worth', 'the', 'watching', 'but', 'it', 'is', 'a', 'terrificly', 'written', 'and', 'performed', 'piece'], ['a', 'masterful', 'production', 'about', 'one', 'of', 'the', 'great', 'master', 's', 'of', 'comedy', 'and', 'his', 'life'], ['the', 'realism', 'really', 'comes', 'home', 'with', 'the', 'little', 'things', 'the', 'fantasy', 'of', 'the', 'guard', 'which', 'rather', 'than', 'use', 'the', 'traditional', 'dream', 'techniques', 'remains', 'solid', 'then', 'disappears'], ['it', 'plays', 'on', 'our', 'knowledge', 'and', 'our', 'senses', 'particularly', 'with', 'the', 'scenes', 'concerning', 'orton', 'and', 'halliwell', 'and', 'the', 'sets', 'particularly', 'of', 'their', 'flat', 'with', 'halliwell', 's', 'murals', 'decorating', 'every', 'surface', 'are', 'terribly', 'well', 'done']] [['i', 'thought', 'this', 'was', 'a', 'wonderful', 'way', 'to', 'spend', 'time', 'on', 'a', 'too', 'hot', 'summer', 'weekend', 'sitting', 'in', 'the', 'air', 'conditioned', 'theater', 'and', 'watching', 'a', 'light', 'hearted', 'comedy'], ['the', 'plot', 'is', 'simplistic', 'but', 'the', 'dialogue', 'is', 'witty', 'and', 'the', 'characters', 'are', 'likable', 'even', 'the', 'well', 'bread', 'suspected', 'serial', 'killer'], ['while', 'some', 'may', 'be', 'disappointed', 'when', 'they', 'realize', 'this', 'is', 'not', 'match', 'point', 'risk', 'addiction', 'i', 'thought', 'it', 'was', 'proof', 'that', 'woody', 'allen', 'is', 'still', 'fully', 'in', 'control', 'of', 'the', 'style', 'many', 'of', 'us', 'have', 'grown', 'to', 'love', 'this', 'was', 'the', 'most', 'i', 'd', 'laughed', 'at', 'one', 'of', 'woody', 's', 'comedies', 'in', 'years', 'dare', 'i', 'say', 'a', 'decade'], ['while', 'i', 've', 'never', 'been', 'impressed', 'with', 'scarlet', 'johanson', 'in', 'this', 'she', 'managed', 'to', 'tone', 'down', 'her', 'sexy', 'image', 'and', 'jumped', 'right', 'into', 'a', 'average', 'but', 'spirited', 'young', 'woman', 'this', 'may', 'not', 'be', 'the', 'crown', 'jewel', 'of', 'his', 'career', 'but', 'it', 'was', 'wittier', 'than', 'devil', 'wears', 'prada', 'and', 'more', 'interesting', 'than', 'superman', 'a', 'great', 'comedy', 'to', 'go', 'see', 'with', 'friends']]\n"]}],"source":["with Pool(4) as p:\n","    sentences = list(tqdm(p.imap(review_to_sentences, data[\"review\"]), total=len(data)))\n","\n","print(len(sentences))\n","print(*sentences[:3])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AY68n0AJCFKp","outputId":"b7ae13f6-a01a-40cf-823c-68d8df579005","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680554505696,"user_tz":-120,"elapsed":374,"user":{"displayName":"Evgeniya Ishkina","userId":"15312785639436921440"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["537072"]},"metadata":{},"execution_count":33}],"source":["flat_sentences = [item for sublist in sentences for item in sublist]\n","len(flat_sentences)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cqb_NOteX-rz"},"outputs":[],"source":["with open('clean_text.txt', 'w') as f:\n","    for s in flat_sentences:\n","        f.write(' '.join(s))\n","        f.write('\\n')"]},{"cell_type":"markdown","metadata":{"id":"qqFhuv7XX-r1"},"source":["On entraîne le modèle et sauvegarde le résultat. \n","\n","Paramètres principaux :\n","* data — doivent être un objet itérable\n","* vector_size — la taille du vecteur, \n","* window — taille de la fenêtre d'observation,\n","* min_count — fréquence minimale d'un mot dans le corpus,\n","* sg — algorithme d'apprentissage utilisé (0 — CBOW, 1 — Skip-gram),\n","* sample — seuil de sous-échantillonnage des mots à haute fréquence,\n","* workers — nombre de threads,\n","* alpha — learning rate,\n","* iter — nombre d'itérations,\n","* max_vocab_size — permet de fixer une limite de mémoire lors de la création du dictionnaire (c'est-à-dire que si la limite est dépassée, les mots de basse fréquence seront écartés). À titre de comparaison : 10 millions de mots = 1 Go de RAM.\n","\n","**Important !** Lors de l'apprentissage d'un modèle il n'y a pas de prétraitement. Cela doit être fait avant l'apprentissage."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OB2FqIioX-r1","outputId":"cde149d7-d359-4ede-a4eb-e8f35353e237","executionInfo":{"status":"ok","timestamp":1680555579410,"user_tz":-120,"elapsed":196019,"user":{"displayName":"Evgeniya Ishkina","userId":"15312785639436921440"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Training model...\n","CPU times: user 4min 29s, sys: 1.12 s, total: 4min 30s\n","Wall time: 3min 15s\n"]}],"source":["print(\"Training model...\")\n","\n","%time model_imdb_en = word2vec.Word2Vec(flat_sentences, workers=4, vector_size=300, min_count=10, window=10, sample=1e-3)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HA3P0CUYX-r4","outputId":"3dbc0998-5db9-42ad-c36b-8cbeb3fbbde5","executionInfo":{"status":"ok","timestamp":1680555584764,"user_tz":-120,"elapsed":221,"user":{"displayName":"Evgeniya Ishkina","userId":"15312785639436921440"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["27864\n"]}],"source":["# La taille du vocabulaire obtenu\n","print(len(model_imdb_en.wv))"]},{"cell_type":"markdown","metadata":{"id":"2mU9sbGYX-r8"},"source":["On fait des premières vérifications manuelles."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n8OQxmUyX-r9","outputId":"88f1eeac-bc6d-4c84-eeb8-2a57c5e305b3","executionInfo":{"status":"ok","timestamp":1680555594000,"user_tz":-120,"elapsed":233,"user":{"displayName":"Evgeniya Ishkina","userId":"15312785639436921440"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[('actress', 0.7802090048789978), ('performer', 0.6007119417190552), ('dancer', 0.5078648924827576)]\n","[('men', 0.545170247554779), ('businessmen', 0.4426037073135376), ('americans', 0.43313008546829224)]\n","[('germany', 0.7680897116661072), ('japan', 0.7602989673614502), ('europe', 0.7565326690673828)]\n","novel\n"]}],"source":["print(model_imdb_en.wv.most_similar(positive=[\"woman\", \"actor\"], negative=[\"man\"], topn=3))\n","print(model_imdb_en.wv.most_similar(positive=[\"dogs\", \"man\"], negative=[\"dog\"], topn=3))\n","print(model_imdb_en.wv.most_similar(\"usa\", topn=3))\n","print(model_imdb_en.wv.doesnt_match(\"comedy thriller western novel\".split()))"]},{"cell_type":"markdown","metadata":{"id":"tudz3Y_2CFK7"},"source":["Cherchons les mots similaires pour le mot `star` :\n","- avec le modèle `model_imdb_en` entraîné sur les critiques des films\n","- avec un autre modèle (`fasttext`) entraîné sur wikipédia"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"egK_nGNqCFK8","outputId":"b04ea3f1-b890-464b-9eca-cd14ca47024d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680555608631,"user_tz":-120,"elapsed":6,"user":{"displayName":"Evgeniya Ishkina","userId":"15312785639436921440"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["('stars', 0.5878415107727051)\n","('hudson', 0.42976656556129456)\n","('hardware', 0.40808263421058655)\n","('singer', 0.40657293796539307)\n","('starred', 0.4049895703792572)\n","('superstar', 0.4049648940563202)\n","('fame', 0.3929443955421448)\n","('napoleonic', 0.3907529413700104)\n","('stardom', 0.38516944646835327)\n","('celebrity', 0.3849700391292572)\n"]}],"source":["print(*model_imdb_en.wv.most_similar(\"star\", topn=10), sep='\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vct5hs9gCFK9","outputId":"b1f25901-d44b-40f1-8605-f96bdfc7d8e1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680555628494,"user_tz":-120,"elapsed":287,"user":{"displayName":"Evgeniya Ishkina","userId":"15312785639436921440"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["0.38497004\n","0.13420257\n","0.16179784\n"]}],"source":["print(model_imdb_en.wv.similarity('star', 'celebrity'))\n","print(model_imdb_en.wv.similarity('star', 'sky'))\n","print(model_imdb_en.wv.similarity('star', 'shine'))"]},{"cell_type":"code","source":["ft_en = fasttext.load_model('/content/drive/My Drive/NLP/cc.en.300.bin')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t6c-YbiXjX--","executionInfo":{"status":"ok","timestamp":1680555740453,"user_tz":-120,"elapsed":231,"user":{"displayName":"Evgeniya Ishkina","userId":"15312785639436921440"}},"outputId":"cc2f652b-5780-49c6-d5e2-f7ee8aa5eb2e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dWgEMObuCFLD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680555871874,"user_tz":-120,"elapsed":227,"user":{"displayName":"Evgeniya Ishkina","userId":"15312785639436921440"}},"outputId":"cd25cfad-7d55-44fd-b076-9d345a5ef5df"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.48565808\n","0.29916823\n","0.28851572\n"]}],"source":["from sklearn.metrics.pairwise import cosine_similarity\n","\n","print(*cosine_similarity([ft_en['star']], [ft_en['celebrity']])[0])\n","print(*cosine_similarity([ft_en['star']], [ft_en['sky']])[0])\n","print(*cosine_similarity([ft_en['star']], [ft_en['shine']])[0])"]},{"cell_type":"code","source":["del ft_en"],"metadata":{"id":"IKrPCi697E21"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"juR4NX0wX-r_"},"source":["### Fine-tuning d'un modèle pré-entraîné\n","\n","Lors de l'apprentissage d'un modèle à partir de zéro, les poids sont initialisés de manière aléatoire. Il est possible d'utiliser des poids d'un modèle pré-entraîné pour initialiser les vecteurs.\n","\n","Utilisons l'[ebook](https://www.gutenberg.org/files/11/11-0.txt) «Alice’s Adventures in Wonderland» pour effectuer un fine-tuning d'un modèle entraîné sur les textes des critiques IMDB."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yHuXJgB_X-sI","outputId":"ee23a954-ed6c-4dc3-9c2a-f6fc868548ae","executionInfo":{"status":"ok","timestamp":1680556615342,"user_tz":-120,"elapsed":355,"user":{"displayName":"Evgeniya Ishkina","userId":"15312785639436921440"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[['alice’s', 'adventures', 'in', 'wonderland', 'by', 'lewis', 'carroll', 'the', 'millennium', 'fulcrum', 'edition', '3.0', 'contents', 'chapter', 'i'], ['down', 'the', 'rabbit-hole', 'chapter', 'ii']]\n"]}],"source":["with open(\"/content/drive/My Drive/NLP/alice.txt\", 'r', encoding='utf-8') as f:\n","    text = f.read()\n","\n","text = re.sub('\\n', ' ', text)\n","sents = sent_tokenize(text)\n","\n","punct = '!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~„“«»†*—/\\-‘’'\n","\n","alice_clean_sents = []\n","for sent in sents:\n","    s = [w.lower().strip(punct) for w in sent.split()]\n","    alice_clean_sents.append(s)\n","    \n","print(alice_clean_sents[:2])"]},{"cell_type":"markdown","metadata":{"id":"dH8f7GNBX-sK"},"source":["Pour faire un tuning d'un modèle, il faut d'abord le sauvegarder et ensuite charger. Tous les paramètres d'entraînement (taille du vecteur, fréquence minimale des mots etc.) seront pris du modèle chargé, on ne peut pas redéfinir leurs valeurs ([la documentation](https://radimrehurek.com/gensim/models/keyedvectors.html))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rv--44TmX-sL","outputId":"b4ccb3be-1eea-4899-c6ca-e14eb2e90df2","executionInfo":{"status":"ok","timestamp":1680556536741,"user_tz":-120,"elapsed":359,"user":{"displayName":"Evgeniya Ishkina","userId":"15312785639436921440"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Saving model...\n"]}],"source":["imdb_model_path = \"/content/drive/My Drive/NLP/IMDB.word2vec\"\n","\n","print(\"Saving model...\")\n","model_imdb_en.save(imdb_model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f6eZwBQzX-sQ","outputId":"e9d15a90-0db5-4d32-ee0d-a2111b8e0b0e","executionInfo":{"status":"ok","timestamp":1680556664860,"user_tz":-120,"elapsed":1260,"user":{"displayName":"Evgeniya Ishkina","userId":"15312785639436921440"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"]},{"output_type":"execute_result","data":{"text/plain":["(91636, 147270)"]},"metadata":{},"execution_count":65}],"source":["model_imdb_alice_en = word2vec.Word2Vec.load(imdb_model_path)\n","\n","model_imdb_alice_en.build_vocab(alice_clean_sents, update=True)\n","model_imdb_alice_en.train(alice_clean_sents, total_examples=model_imdb_alice_en.corpus_count, epochs=5)"]},{"cell_type":"markdown","metadata":{"id":"nMLhISWiX-sS"},"source":["Comparons la similarité des mots `white` et `rabbit` calculée avec le modèle initial avec celle calculée avec le modèle fine-tuned."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oMMFYX-ZCFLO","outputId":"14cce841-e49f-45a7-9f5c-d41d3c7ae89d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680556702003,"user_tz":-120,"elapsed":5,"user":{"displayName":"Evgeniya Ishkina","userId":"15312785639436921440"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["0.29565364\n","0.36994138\n"]}],"source":["print(model_imdb_en.wv.similarity('white', 'rabbit'))\n","print(model_imdb_alice_en.wv.similarity('white', 'rabbit'))"]},{"cell_type":"markdown","metadata":{"id":"8fNNkS5QCFLP"},"source":["## Classification des critiques IMDB avec Word2Vec"]},{"cell_type":"markdown","metadata":{"id":"bLIbjSTXCFLR"},"source":["### Préparation des données\n","\n","* Faire un prétraitement des données.\n","\n","* Diviser le dataset initial IMDB en ensemble pour l'apprentissage et pour le test.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"kpdVFhmaCFLb"},"source":["### Entraînement d'un modèle de classification\n","\n","* Entraîner et sauvegarder un modèle word2vec sur les données d'entraînement.\n","\n","* Vectoriser les documents (le modèle `Word2Vec` contient les vecteurs des mots).\n","\n","  * **Option 1** `MeanEmbeddingVectorizer` : pour chaque document calculez un vecteur correspondant à la moyenne des vecteurs des mots du vocabulaire qui apparaissent dans ce document.\n","  * **Option 2** `TfidfEmbeddingVectorizer` : pour chaque document calculez un vecteur correspondant à la moyenne pondérée des vecteurs des mots du vocabulaire qui apparaissent dans ce document, avec des poids *tf-idf*.\n","\n","* Entraîner un modèle avec chacun des deux vectorisateurs. Pour cela, utiliser `sklearn.pipeline` avec deux étapes : vectorisation et application d'un algorithme de classiffication de votre choix.\n"]},{"cell_type":"markdown","source":["#### MeanEmbeddingVectorizer"],"metadata":{"id":"okUhPjv56pdT"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z64fzsstCFLg"},"outputs":[],"source":["import numpy as np\n","\n","class MeanEmbeddingVectorizer(object):\n","    def __init__(self, word2vec):\n","        self.word2vec = word2vec\n","        self.dim = len(list(word2vec.values())[0])\n","\n","    def fit(self, X, y):\n","        return self\n","\n","    def transform(self, X):\n","        return np.array([\n","            np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n","                    or [np.zeros(self.dim)], axis=0)\n","            for words in X\n","        ])"]},{"cell_type":"markdown","source":["#### TfidfEmbeddingVectorizer"],"metadata":{"id":"9Pi7gMDD6sTQ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"mixcn5MgCFLi"},"outputs":[],"source":["from collections import defaultdict\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","class TfidfEmbeddingVectorizer(object):\n","    def __init__(self, word2vec):\n","        self.word2vec = word2vec\n","        self.word2weight = None\n","        self.dim = len(list(word2vec.values())[0])\n","\n","    def fit(self, X, y):\n","        tfidf = TfidfVectorizer(analyzer=lambda x: x)\n","        tfidf.fit(X)\n","        max_idf = max(tfidf.idf_)\n","        self.word2weight = defaultdict(\n","            lambda: max_idf,\n","            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n","\n","        return self\n","\n","    def transform(self, X):\n","        return np.array([\n","                np.mean([self.word2vec[w] * self.word2weight[w]\n","                         for w in words if w in self.word2vec] or\n","                        [np.zeros(self.dim)], axis=0)\n","                for words in X\n","            ])"]},{"cell_type":"markdown","metadata":{"id":"r21Z2Mu3CFLj"},"source":["Convertir le modèle Word2Vec en dictionnaire qui sera utilisé ensuite pour la vectorisation des textes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W9iDsBiFCFLj"},"outputs":[],"source":["w2v_dict = dict(zip(w2v_model.wv.index_to_key, w2v_model.wv.vectors))"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"pDnz3uQKCFLm","executionInfo":{"status":"ok","timestamp":1680594060524,"user_tz":-120,"elapsed":264,"user":{"displayName":"Evgeniya Ishkina","userId":"15312785639436921440"}}},"outputs":[],"source":["# your code here"]},{"cell_type":"markdown","source":["### Evaluation du modèle de classification\n","\n","* Faire des prédictions sur les données de test avec chacun des deux modèles obtenus à l'étape précédente\n","\n","* Afficher la matrice de confusion et les valeurs des métriques suivantes : `precision_score`, `recall_score`, `f1_score`, `accuracy_score`"],"metadata":{"id":"GJtpimzn648D"}},{"cell_type":"markdown","source":["#### MeanEmbeddingVectorizer"],"metadata":{"id":"GNXgm4Y-7LJY"}},{"cell_type":"code","execution_count":19,"metadata":{"id":"t4tE6M7YCFLn","executionInfo":{"status":"ok","timestamp":1680594299832,"user_tz":-120,"elapsed":253,"user":{"displayName":"Evgeniya Ishkina","userId":"15312785639436921440"}}},"outputs":[],"source":["# your code here"]},{"cell_type":"markdown","source":["#### TfidfEmbeddingVectorizer "],"metadata":{"id":"VMxJAlme7RWv"}},{"cell_type":"code","execution_count":20,"metadata":{"id":"rew2NOsnCFLr","scrolled":false,"executionInfo":{"status":"ok","timestamp":1680594320166,"user_tz":-120,"elapsed":725,"user":{"displayName":"Evgeniya Ishkina","userId":"15312785639436921440"}}},"outputs":[],"source":["# your code here"]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0c838ab8723146f480cc6368657590c5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4d321c1988b744929c660d9a18e93a1d","IPY_MODEL_c0c43adbc9b946ee8f07c6c80f562a89","IPY_MODEL_ac0f910945c344de99abf6babe8b6de7"],"layout":"IPY_MODEL_7e6b7c3b4d1e46c2a84242100d0abfa7"}},"4d321c1988b744929c660d9a18e93a1d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f38a0cedf6fe4ac4802ba5c48dcd9bff","placeholder":"​","style":"IPY_MODEL_2598fd66c334422cb87f21e01418286c","value":"100%"}},"c0c43adbc9b946ee8f07c6c80f562a89":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc5d696d5c1846a382c7b602b971ad29","max":50000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_08b7866d34144d119e3a5f493dd172ea","value":50000}},"ac0f910945c344de99abf6babe8b6de7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c9d120308f884283a8be29b4f002df1d","placeholder":"​","style":"IPY_MODEL_4f92d894df644589a4429c6cde910e59","value":" 50000/50000 [03:28&lt;00:00, 278.27it/s]"}},"7e6b7c3b4d1e46c2a84242100d0abfa7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f38a0cedf6fe4ac4802ba5c48dcd9bff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2598fd66c334422cb87f21e01418286c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fc5d696d5c1846a382c7b602b971ad29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08b7866d34144d119e3a5f493dd172ea":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c9d120308f884283a8be29b4f002df1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f92d894df644589a4429c6cde910e59":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}